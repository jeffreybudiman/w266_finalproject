{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tabulate_results.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7jwBFG9m2ug",
        "outputId": "9feaa151-74f6-4a23-de96-d525eb497b72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkpoomd72JgP",
        "outputId": "cf49fb44-3310-46bd-dbe3-6416f38791d3"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 64.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.63.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.11.1+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 68.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 49.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.11.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 73.0 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 65.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120747 sha256=44797c4d6bbf91a9fc8b043eb90c95821e1029acc9fadefe0241435b607d1e3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/c0/df/b6873ab7aac3f2465aa9144b6b4c41c4391cfecc027c8b07e7\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 sentence-transformers-2.2.0 sentencepiece-0.1.96 tokenizers-0.11.6 transformers-4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUdvXdO3IJGg",
        "outputId": "3403fd41-d3b5-426b-a07f-ea8320a8ec36"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE-M10JxKNbU",
        "outputId": "094f4457-9609-4761-936e-8f4f1a90ea0b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "cZb-4D4oR8VV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9viEgt7vZxeE",
        "outputId": "14d0173b-416c-4211-e995-22922b63c05d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "-p1BNPcFZ15X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task = \"classify_conds\"\n",
        "experiment_type = 1\n",
        "numrows = 0\n",
        "augment_type = \"none\"\n",
        "\n",
        "batch_size = 16\n",
        "learning_rate = 3e-5\n",
        "weight_decay = 0.01\n",
        "num_train_epochs = 1"
      ],
      "metadata": {
        "id": "73z8t22BSQTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filename\n",
        "filename = \"task-\"+task+\"_\"+\"exp-\"+str(experiment_type)+\"_\"+\"rows-\"+str(numrows)+\"_\"+\"agument-\"+augment_type\n",
        "filename"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9G4jY4Brarvn",
        "outputId": "7e6ac008-a829-4adc-d944-cdf90c93f8e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'task-classify_conds_exp-1_rows-0_agument-none'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save result\n",
        "projpath = \"/content/drive/MyDrive/UCB_MIDS/W266\"\n",
        "\n",
        "#saved_file = os.path.join(projpath, \"saved_results\",filename)"
      ],
      "metadata": {
        "id": "uFkKU3sUZuia"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class tabulateResults:\n",
        "  \"\"\" Tabulates results\n",
        "  \"\"\"\n",
        "  def __init__(self, translate_file=None, agg_file=None, sel_file=None, conds_file=None):\n",
        "    self.translate_file = translate_file\n",
        "    self.agg_file = agg_file\n",
        "    self.sel_file = sel_file\n",
        "    self.conds_file = conds_file\n",
        "    self.agg_exists = False\n",
        "    self.sel_exists = False\n",
        "    self.conds_exists = False\n",
        "    self.dd = {\"AGG\": [\"\"], \"SEL\": [\"\"], \"CONDS\": [\"\"], \"EX\": [\"\"]}\n",
        "\n",
        "    # read input files\n",
        "    if self.translate_file != None:\n",
        "      # set flags\n",
        "      self.agg_exists, self.sel_exists, self.conds_exists = True, True, True\n",
        "      # read json data\n",
        "      self.trans_df = self.readfile(self.translate_file)\n",
        "      # create AGG df\n",
        "      self.agg_df = pd.DataFrame({})\n",
        "      self.agg_df[\"pred_label\"] = self.trans_df[\"pred_label\"].apply(lambda x: self.extractAgg(x))\n",
        "      self.agg_df[\"true_label\"] = self.trans_df[\"true_label\"].apply(lambda x: self.extractAgg(x))\n",
        "      # create SEL df\n",
        "      self.sel_df = pd.DataFrame({})\n",
        "      self.sel_df[\"pred_label\"] = self.trans_df[\"pred_label\"].apply(lambda x: self.extractSel(x))\n",
        "      self.sel_df[\"true_label\"] = self.trans_df[\"true_label\"].apply(lambda x: self.extractSel(x))\n",
        "      # create CONDS df\n",
        "      self.conds_df = pd.DataFrame({})\n",
        "      self.conds_df[\"pred_label\"] = self.trans_df[\"pred_label\"].apply(lambda x: self.extractConds(x))\n",
        "      self.conds_df[\"true_label\"] = self.trans_df[\"true_label\"].apply(lambda x: self.extractConds(x))\n",
        "    else:\n",
        "      if self.agg_file != None:\n",
        "        self.agg_df = self.readfile(self.agg_file)\n",
        "        self.agg_exists = True\n",
        "      if self.sel_file != None:\n",
        "        self.sel_df = self.readfile(self.sel_file)\n",
        "        self.sel_exists = True\n",
        "      if self.conds_file != None:\n",
        "        self.conds_df = self.readfile(self.conds_file)\n",
        "        self.conds_exists = True\n",
        "    \n",
        "    # AGG\n",
        "    if self.agg_exists:\n",
        "      # process each cond\n",
        "      self.agg_df[\"true_label_proc\"] = self.agg_df.true_label.apply(lambda x: self.processAggSel(x))\n",
        "      self.agg_df[\"pred_label_proc\"] = self.agg_df.pred_label.apply(lambda x: self.processAggSel(x))\n",
        "      # evaluate match\n",
        "      self.agg_df[\"match\"] = self.agg_df.apply(lambda x: self.stringEqual(x[\"pred_label_proc\"], x[\"true_label_proc\"]), axis=1)\n",
        "      # calculate accuracy\n",
        "      self.dd[\"AGG\"] = [round(100*self.agg_df[\"match\"].mean(axis=0),1)]\n",
        "\n",
        "    # SEL\n",
        "    if self.sel_exists:\n",
        "      # process each cond\n",
        "      self.sel_df[\"true_label_proc\"] = self.sel_df.true_label.apply(lambda x: self.processAggSel(x))\n",
        "      self.sel_df[\"pred_label_proc\"] = self.sel_df.pred_label.apply(lambda x: self.processAggSel(x))\n",
        "      # evaluate match\n",
        "      self.sel_df[\"match\"] = self.sel_df.apply(lambda x: self.stringEqual(x[\"pred_label_proc\"], x[\"true_label_proc\"]), axis=1)\n",
        "      # calculate accuracy\n",
        "      self.dd[\"SEL\"] = [round(100*self.sel_df[\"match\"].mean(axis=0),1)]\n",
        "\n",
        "    # CONDS\n",
        "    if self.conds_exists:\n",
        "      # process each cond\n",
        "      self.conds_df[\"true_label_proc\"] = self.conds_df.true_label.apply(lambda x: self.processConds(x))\n",
        "      self.conds_df[\"pred_label_proc\"] = self.conds_df.pred_label.apply(lambda x: self.processConds(x))\n",
        "      # get condition count\n",
        "      self.conds_df[\"true_numconds\"] = self.conds_df.true_label_proc.apply(lambda x: self.countConds(x))\n",
        "      self.conds_df[\"pred_numconds\"] = self.conds_df.pred_label_proc.apply(lambda x: self.countConds(x))\n",
        "      # evaluate match\n",
        "      self.conds_df[\"match\"] = self.conds_df.apply(lambda x: self.stringEqual(x[\"pred_label_proc\"], x[\"true_label_proc\"]), axis=1)\n",
        "      # calculate accuracy    \n",
        "      self.dd[\"CONDS\"] = [round(100*self.conds_df[\"match\"].mean(axis=0),1)]\n",
        "\n",
        "    # calculate overall Execution accuracy\n",
        "    if  self.agg_exists and self.sel_exists and self.conds_exists:\n",
        "      # get each type's match\n",
        "      a = np.array(self.agg_df[\"match\"])\n",
        "      s = np.array(self.sel_df[\"match\"])\n",
        "      c = np.array(self.conds_df[\"match\"])\n",
        "      # calculate overall EX match\n",
        "      ex_match = a*s*c\n",
        "      ex_match = round(100*ex_match.mean(),1)\n",
        "      self.dd[\"EX\"] = [ex_match]\n",
        "\n",
        "    # generate final dataframe\n",
        "    self.table = pd.DataFrame(self.dd)\n",
        "\n",
        "  def readfile(self, file):\n",
        "    \"\"\" Read input json file and take the second json element (the first one\n",
        "        is only a header)\n",
        "    \"\"\"\n",
        "    with open(file) as f:\n",
        "      lines = f.readlines()\n",
        "    count = 0\n",
        "    for line in lines:\n",
        "      d = json.loads(line.strip())\n",
        "      if count == 0:\n",
        "        pass\n",
        "      else:\n",
        "        df = pd.DataFrame(d)\n",
        "      count += 1\n",
        "    return df\n",
        "\n",
        "  def extractAgg(self, txt):\n",
        "    \"\"\" Extract AGG from pred and true labels of translate df \n",
        "    \"\"\"\n",
        "    pattern = r'\\((.*?)\\)'\n",
        "    d = re.findall(pattern, txt)\n",
        "    if d == []:\n",
        "      agg = \"\"\n",
        "    else:\n",
        "      agg = d[0]\n",
        "    return agg\n",
        "\n",
        "  def extractSel(self, txt):\n",
        "    \"\"\" Extract SEL from pred and true labels of translate df \n",
        "    \"\"\"\n",
        "    pattern = r'\\[(.*?)\\]'\n",
        "    d = re.findall(pattern, txt)\n",
        "    if d != []:\n",
        "      sel = d[0]\n",
        "    else:\n",
        "      sel = \"\"\n",
        "    return sel\n",
        "\n",
        "  def extractConds(self, txt):\n",
        "    \"\"\" Extract CONDS from pred and true labels of translate df \n",
        "    \"\"\"\n",
        "    pattern = r'\\[(.*?)\\]'\n",
        "    d = re.findall(pattern, txt)\n",
        "    conds = \"\".join([\"[\"+n.replace(\"'\", \"\")+\"]\" for n in d[2:]])\n",
        "    return conds\n",
        "\n",
        "  def processAggSel(self, txt):\n",
        "    \"\"\" Strip, lowercase\n",
        "    \"\"\"\n",
        "    return txt.strip().lower()\n",
        "\n",
        "  def processConds(self, txt):\n",
        "    \"\"\" Extract each where condition and post process it (strip, lowercase, sort for comparison).\n",
        "    \"\"\"\n",
        "    pattern = r'\\[(.*?)\\]'\n",
        "    extr_conds = re.findall(pattern, txt)\n",
        "    out = [c.strip().lower() for c in extr_conds]\n",
        "    out.sort()\n",
        "    return out\n",
        "\n",
        "  def countConds(self, condlist):\n",
        "    \"\"\" Count where conditions\n",
        "    \"\"\"\n",
        "    return len(condlist) \n",
        "  \n",
        "  def stringEqual(self, txt1, txt2):\n",
        "    \"\"\" Check two strings or lists if they are equal\n",
        "    \"\"\"\n",
        "    if txt1 == txt2:\n",
        "      out = 1\n",
        "    else:\n",
        "      out = 0\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "R3t74FX0CXdM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FMKUbONW03EX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Direct Translate Result"
      ],
      "metadata": {
        "id": "BzVTFe7oXccd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task = \"translate\"\n",
        "\n",
        "experiment_type = 0\n",
        "numrows = 0\n",
        "augment_type = \"none\"\n",
        "filename = \"task-\"+task+\"_\"+\"exp-\"+str(experiment_type)+\"_\"+\"rows-\"+str(numrows)+\"_\"+\"agument-\"+augment_type\n",
        "file = os.path.join(projpath, \"saved_results\",filename)\n",
        "trans_exp0 = tabulateResults(translate_file=file)  "
      ],
      "metadata": {
        "id": "hsT8yK_aeg2r"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_type = 1\n",
        "numrows = 0\n",
        "augment_type = \"none\"\n",
        "filename = \"task-\"+task+\"_\"+\"exp-\"+str(experiment_type)+\"_\"+\"rows-\"+str(numrows)+\"_\"+\"agument-\"+augment_type\n",
        "file = os.path.join(projpath, \"saved_results\",filename)\n",
        "trans_exp1 = tabulateResults(translate_file=file)"
      ],
      "metadata": {
        "id": "LOc48jsM21BY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_type = 2\n",
        "numrows = 0\n",
        "augment_type = \"none\"\n",
        "filename = \"task-\"+task+\"_\"+\"exp-\"+str(experiment_type)+\"_\"+\"rows-\"+str(numrows)+\"_\"+\"agument-\"+augment_type\n",
        "file = os.path.join(projpath, \"saved_results\",filename)\n",
        "trans_exp2 = tabulateResults(translate_file=file)"
      ],
      "metadata": {
        "id": "rRrEO--SX71S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_type = 1\n",
        "numrows = 0\n",
        "augment_type = \"column\"\n",
        "filename = \"task-\"+task+\"_\"+\"exp-\"+str(experiment_type)+\"_\"+\"rows-\"+str(numrows)+\"_\"+\"agument-\"+augment_type\n",
        "file = os.path.join(projpath, \"saved_results\",filename)\n",
        "trans_exp1_aug = tabulateResults(translate_file=file)"
      ],
      "metadata": {
        "id": "FbDZBOZZ6ysw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_type = 0\n",
        "numrows = 0\n",
        "augment_type = \"column\"\n",
        "filename = \"task-\"+task+\"_\"+\"exp-\"+str(experiment_type)+\"_\"+\"rows-\"+str(numrows)+\"_\"+\"agument-\"+augment_type\n",
        "file = os.path.join(projpath, \"saved_results\",filename)\n",
        "trans_exp0_aug = tabulateResults(translate_file=file)"
      ],
      "metadata": {
        "id": "nW410ewn3TuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_type = 0\n",
        "numrows = 0\n",
        "augment_type = \"synonym\"\n",
        "filename = \"task-\"+task+\"_\"+\"exp-\"+str(experiment_type)+\"_\"+\"rows-\"+str(numrows)+\"_\"+\"agument-\"+augment_type+\"1\"\n",
        "file = os.path.join(projpath, \"saved_results\",filename)\n",
        "trans_exp0_aug_syn1 = tabulateResults(translate_file=file)"
      ],
      "metadata": {
        "id": "U12Bk5ouKbEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_type = 0\n",
        "numrows = 0\n",
        "augment_type = \"synonym\"\n",
        "filename = \"task-\"+task+\"_\"+\"exp-\"+str(experiment_type)+\"_\"+\"rows-\"+str(numrows)+\"_\"+\"agument-\"+augment_type+\"2\"\n",
        "file = os.path.join(projpath, \"saved_results\",filename)\n",
        "trans_exp0_aug_syn2 = tabulateResults(translate_file=file)"
      ],
      "metadata": {
        "id": "VqjbdDXDRT7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_type = 3\n",
        "numrows = 1\n",
        "augment_type = \"none\"\n",
        "filename = \"task-\"+task+\"_\"+\"exp-\"+str(experiment_type)+\"_\"+\"rows-\"+str(numrows)+\"_\"+\"agument-\"+augment_type\n",
        "file = os.path.join(projpath, \"saved_results\",filename)\n",
        "trans_exp3 = tabulateResults(translate_file=file)"
      ],
      "metadata": {
        "id": "wCSWJdvWxMCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_type = 1\n",
        "numrows = 0\n",
        "augment_type = \"synonym\"\n",
        "filename = \"task-\"+task+\"_\"+\"exp-\"+str(experiment_type)+\"_\"+\"rows-\"+str(numrows)+\"_\"+\"agument-\"+augment_type+\"2\"\n",
        "file = os.path.join(projpath, \"saved_results\",filename)\n",
        "trans_exp1_aug_syn2 = tabulateResults(translate_file=file)"
      ],
      "metadata": {
        "id": "kfaiDpqT-uqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans_exp3.table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "V3lcjMpKxylZ",
        "outputId": "3647a512-99b5-4576-f154-949b9cb596a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    AGG   SEL  CONDS    EX\n",
              "0  86.8  92.3   73.3  62.3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c95efe2c-bb9f-4f04-b0f4-d1d6825cd810\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AGG</th>\n",
              "      <th>SEL</th>\n",
              "      <th>CONDS</th>\n",
              "      <th>EX</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86.8</td>\n",
              "      <td>92.3</td>\n",
              "      <td>73.3</td>\n",
              "      <td>62.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c95efe2c-bb9f-4f04-b0f4-d1d6825cd810')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c95efe2c-bb9f-4f04-b0f4-d1d6825cd810 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c95efe2c-bb9f-4f04-b0f4-d1d6825cd810');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finaltable_trans = pd.concat([trans_exp0.table, trans_exp1.table, trans_exp2.table, trans_exp3.table,\n",
        "                              trans_exp1_aug.table, trans_exp0_aug.table, \n",
        "                              trans_exp0_aug_syn1.table, trans_exp0_aug_syn2.table, trans_exp1_aug_syn2.table])\n",
        "finaltable_trans[\"Experiment\"] = [\"Standard\", \"+Schema\", \"+Schema ColTypes\", \"+Schema+ColTypes+Vals\",\n",
        "                                  \"+Schema&Augmentation\", \"Augmentation\", \"Augmentation Synonym1\", \"Augmentation Synonym2\",\n",
        "                                  \"+Schema&Augmentation Synonym2\"]\n",
        "finaltable_trans = finaltable_trans.set_index('Experiment')\n",
        "finaltable_trans.style.set_properties(**{'text-align': 'left'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "qMzx45SDj-lW",
        "outputId": "dae70128-506d-47ef-9e49-e04ed04469bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f463270f750>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_5feb9_row0_col0, #T_5feb9_row0_col1, #T_5feb9_row0_col2, #T_5feb9_row0_col3, #T_5feb9_row1_col0, #T_5feb9_row1_col1, #T_5feb9_row1_col2, #T_5feb9_row1_col3, #T_5feb9_row2_col0, #T_5feb9_row2_col1, #T_5feb9_row2_col2, #T_5feb9_row2_col3, #T_5feb9_row3_col0, #T_5feb9_row3_col1, #T_5feb9_row3_col2, #T_5feb9_row3_col3, #T_5feb9_row4_col0, #T_5feb9_row4_col1, #T_5feb9_row4_col2, #T_5feb9_row4_col3, #T_5feb9_row5_col0, #T_5feb9_row5_col1, #T_5feb9_row5_col2, #T_5feb9_row5_col3, #T_5feb9_row6_col0, #T_5feb9_row6_col1, #T_5feb9_row6_col2, #T_5feb9_row6_col3, #T_5feb9_row7_col0, #T_5feb9_row7_col1, #T_5feb9_row7_col2, #T_5feb9_row7_col3, #T_5feb9_row8_col0, #T_5feb9_row8_col1, #T_5feb9_row8_col2, #T_5feb9_row8_col3 {\n",
              "  text-align: left;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_5feb9_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >AGG</th>\n",
              "      <th class=\"col_heading level0 col1\" >SEL</th>\n",
              "      <th class=\"col_heading level0 col2\" >CONDS</th>\n",
              "      <th class=\"col_heading level0 col3\" >EX</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >Experiment</th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "      <th class=\"blank col1\" >&nbsp;</th>\n",
              "      <th class=\"blank col2\" >&nbsp;</th>\n",
              "      <th class=\"blank col3\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_5feb9_level0_row0\" class=\"row_heading level0 row0\" >Standard</th>\n",
              "      <td id=\"T_5feb9_row0_col0\" class=\"data row0 col0\" >84.200000</td>\n",
              "      <td id=\"T_5feb9_row0_col1\" class=\"data row0 col1\" >65.700000</td>\n",
              "      <td id=\"T_5feb9_row0_col2\" class=\"data row0 col2\" >46.000000</td>\n",
              "      <td id=\"T_5feb9_row0_col3\" class=\"data row0 col3\" >32.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5feb9_level0_row1\" class=\"row_heading level0 row1\" >+Schema</th>\n",
              "      <td id=\"T_5feb9_row1_col0\" class=\"data row1 col0\" >86.900000</td>\n",
              "      <td id=\"T_5feb9_row1_col1\" class=\"data row1 col1\" >93.300000</td>\n",
              "      <td id=\"T_5feb9_row1_col2\" class=\"data row1 col2\" >74.100000</td>\n",
              "      <td id=\"T_5feb9_row1_col3\" class=\"data row1 col3\" >63.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5feb9_level0_row2\" class=\"row_heading level0 row2\" >+Schema ColTypes</th>\n",
              "      <td id=\"T_5feb9_row2_col0\" class=\"data row2 col0\" >87.100000</td>\n",
              "      <td id=\"T_5feb9_row2_col1\" class=\"data row2 col1\" >92.900000</td>\n",
              "      <td id=\"T_5feb9_row2_col2\" class=\"data row2 col2\" >73.100000</td>\n",
              "      <td id=\"T_5feb9_row2_col3\" class=\"data row2 col3\" >62.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5feb9_level0_row3\" class=\"row_heading level0 row3\" >+Schema+ColTypes+Vals</th>\n",
              "      <td id=\"T_5feb9_row3_col0\" class=\"data row3 col0\" >86.800000</td>\n",
              "      <td id=\"T_5feb9_row3_col1\" class=\"data row3 col1\" >92.300000</td>\n",
              "      <td id=\"T_5feb9_row3_col2\" class=\"data row3 col2\" >73.300000</td>\n",
              "      <td id=\"T_5feb9_row3_col3\" class=\"data row3 col3\" >62.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5feb9_level0_row4\" class=\"row_heading level0 row4\" >+Schema&Augmentation</th>\n",
              "      <td id=\"T_5feb9_row4_col0\" class=\"data row4 col0\" >87.600000</td>\n",
              "      <td id=\"T_5feb9_row4_col1\" class=\"data row4 col1\" >93.800000</td>\n",
              "      <td id=\"T_5feb9_row4_col2\" class=\"data row4 col2\" >78.300000</td>\n",
              "      <td id=\"T_5feb9_row4_col3\" class=\"data row4 col3\" >66.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5feb9_level0_row5\" class=\"row_heading level0 row5\" >Augmentation</th>\n",
              "      <td id=\"T_5feb9_row5_col0\" class=\"data row5 col0\" >84.600000</td>\n",
              "      <td id=\"T_5feb9_row5_col1\" class=\"data row5 col1\" >69.000000</td>\n",
              "      <td id=\"T_5feb9_row5_col2\" class=\"data row5 col2\" >52.300000</td>\n",
              "      <td id=\"T_5feb9_row5_col3\" class=\"data row5 col3\" >37.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5feb9_level0_row6\" class=\"row_heading level0 row6\" >Augmentation Synonym1</th>\n",
              "      <td id=\"T_5feb9_row6_col0\" class=\"data row6 col0\" >84.100000</td>\n",
              "      <td id=\"T_5feb9_row6_col1\" class=\"data row6 col1\" >61.500000</td>\n",
              "      <td id=\"T_5feb9_row6_col2\" class=\"data row6 col2\" >43.700000</td>\n",
              "      <td id=\"T_5feb9_row6_col3\" class=\"data row6 col3\" >27.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5feb9_level0_row7\" class=\"row_heading level0 row7\" >Augmentation Synonym2</th>\n",
              "      <td id=\"T_5feb9_row7_col0\" class=\"data row7 col0\" >83.300000</td>\n",
              "      <td id=\"T_5feb9_row7_col1\" class=\"data row7 col1\" >57.200000</td>\n",
              "      <td id=\"T_5feb9_row7_col2\" class=\"data row7 col2\" >40.300000</td>\n",
              "      <td id=\"T_5feb9_row7_col3\" class=\"data row7 col3\" >25.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5feb9_level0_row8\" class=\"row_heading level0 row8\" >+Schema&Augmentation Synonym2</th>\n",
              "      <td id=\"T_5feb9_row8_col0\" class=\"data row8 col0\" >86.200000</td>\n",
              "      <td id=\"T_5feb9_row8_col1\" class=\"data row8 col1\" >90.300000</td>\n",
              "      <td id=\"T_5feb9_row8_col2\" class=\"data row8 col2\" >68.300000</td>\n",
              "      <td id=\"T_5feb9_row8_col3\" class=\"data row8 col3\" >56.300000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write csv\n",
        "csv_file = os.path.join(projpath, \"saved_results\", \"finaltable_trans.csv\")\n",
        "finaltable_trans.to_csv(csv_file)\n"
      ],
      "metadata": {
        "id": "gRJhFuYqGlSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Slot Prediction Result\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "f_Fo_otac0Ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tasks = [\"classify_agg\", \"classify_sel\", \"classify_conds\"]"
      ],
      "metadata": {
        "id": "2kznKa77czSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_type = 0\n",
        "numrows = 0\n",
        "augment_type = \"none\"\n",
        "\n",
        "def genfilename(tasks, experiment_type, numrows=0, augment_type=\"none\"):\n",
        "  files = []\n",
        "  for task in tasks:\n",
        "    filename = \"task-\"+task+\"_\"+\"exp-\"+str(experiment_type)+\"_\"+\"rows-\"+str(numrows)+\"_\"+\"agument-\"+augment_type\n",
        "    name = os.path.join(projpath, \"saved_results\",filename)\n",
        "    files.append(name)\n",
        "  return files\n",
        "\n",
        "files = genfilename(tasks, experiment_type, numrows, augment_type)\n",
        "exp0 = tabulateResults(agg_file=files[0], sel_file=files[1], conds_file=files[2])\n"
      ],
      "metadata": {
        "id": "rLVpwGetcnQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_type = 1\n",
        "numrows = 0\n",
        "augment_type = \"none\"\n",
        "\n",
        "def genfilename(tasks, experiment_type, numrows=0, augment_type=\"none\"):\n",
        "  files = []\n",
        "  for task in tasks:\n",
        "    filename = \"task-\"+task+\"_\"+\"exp-\"+str(experiment_type)+\"_\"+\"rows-\"+str(numrows)+\"_\"+\"agument-\"+augment_type\n",
        "    name = os.path.join(projpath, \"saved_results\",filename)\n",
        "    files.append(name)\n",
        "  return files\n",
        "\n",
        "files = genfilename(tasks, experiment_type, numrows, augment_type)\n",
        "exp1 = tabulateResults(agg_file=files[0], sel_file=files[1], conds_file=files[2])\n"
      ],
      "metadata": {
        "id": "Y49n5mz3zeNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_type = 1\n",
        "numrows = 0\n",
        "augment_type = \"column\"\n",
        "\n",
        "def genfilename(tasks, experiment_type, numrows=0, augment_type=\"none\"):\n",
        "  files = []\n",
        "  for task in tasks:\n",
        "    filename = \"task-\"+task+\"_\"+\"exp-\"+str(experiment_type)+\"_\"+\"rows-\"+str(numrows)+\"_\"+\"agument-\"+augment_type\n",
        "    name = os.path.join(projpath, \"saved_results\",filename)\n",
        "    files.append(name)\n",
        "  return files\n",
        "\n",
        "files = genfilename(tasks, experiment_type, numrows, augment_type)\n",
        "exp1_aug = tabulateResults(agg_file=files[0], sel_file=files[1], conds_file=files[2])"
      ],
      "metadata": {
        "id": "5xvl0T19c9JX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_type = 1\n",
        "numrows = 0\n",
        "augment_type = \"synonym\"\n",
        "\n",
        "def genfilename(tasks, experiment_type, numrows=0, augment_type=\"none\"):\n",
        "  files = []\n",
        "  for task in tasks:\n",
        "    filename = \"task-\"+task+\"_\"+\"exp-\"+str(experiment_type)+\"_\"+\"rows-\"+str(numrows)+\"_\"+\"agument-\"+augment_type\n",
        "    name = os.path.join(projpath, \"saved_results\",filename)\n",
        "    files.append(name)\n",
        "  return files\n",
        "\n",
        "files = genfilename(tasks, experiment_type, numrows, augment_type)\n",
        "exp1_aug_syn = tabulateResults(agg_file=None, sel_file=None, conds_file=files[2])"
      ],
      "metadata": {
        "id": "T1sM2h7Jn4lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finaltable = pd.concat([exp0.table, exp1.table, exp1_aug.table, exp1_aug_syn.table])\n",
        "finaltable[\"Experiment\"] = [\"Standard\", \"+Schema\", \"+Schema&AugColumn\", \"+Schema&AugSynonym\"]\n",
        "finaltable = finaltable.set_index('Experiment')\n",
        "finaltable.style.set_properties(**{'text-align': 'left'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pChdE8rEsks4",
        "outputId": "d9843fe1-acfd-4b24-b7e3-090a1e8975ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fb1c1b56b50>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_80b8b_row0_col0, #T_80b8b_row0_col1, #T_80b8b_row0_col2, #T_80b8b_row0_col3, #T_80b8b_row1_col0, #T_80b8b_row1_col1, #T_80b8b_row1_col2, #T_80b8b_row1_col3, #T_80b8b_row2_col0, #T_80b8b_row2_col1, #T_80b8b_row2_col2, #T_80b8b_row2_col3, #T_80b8b_row3_col0, #T_80b8b_row3_col1, #T_80b8b_row3_col2, #T_80b8b_row3_col3 {\n",
              "  text-align: left;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_80b8b_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >AGG</th>\n",
              "      <th class=\"col_heading level0 col1\" >SEL</th>\n",
              "      <th class=\"col_heading level0 col2\" >CONDS</th>\n",
              "      <th class=\"col_heading level0 col3\" >EX</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >Experiment</th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "      <th class=\"blank col1\" >&nbsp;</th>\n",
              "      <th class=\"blank col2\" >&nbsp;</th>\n",
              "      <th class=\"blank col3\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_80b8b_level0_row0\" class=\"row_heading level0 row0\" >Standard</th>\n",
              "      <td id=\"T_80b8b_row0_col0\" class=\"data row0 col0\" >88.900000</td>\n",
              "      <td id=\"T_80b8b_row0_col1\" class=\"data row0 col1\" >72.000000</td>\n",
              "      <td id=\"T_80b8b_row0_col2\" class=\"data row0 col2\" >45.400000</td>\n",
              "      <td id=\"T_80b8b_row0_col3\" class=\"data row0 col3\" >33.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_80b8b_level0_row1\" class=\"row_heading level0 row1\" >+Schema</th>\n",
              "      <td id=\"T_80b8b_row1_col0\" class=\"data row1 col0\" >89.400000</td>\n",
              "      <td id=\"T_80b8b_row1_col1\" class=\"data row1 col1\" >92.100000</td>\n",
              "      <td id=\"T_80b8b_row1_col2\" class=\"data row1 col2\" >71.800000</td>\n",
              "      <td id=\"T_80b8b_row1_col3\" class=\"data row1 col3\" >60.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_80b8b_level0_row2\" class=\"row_heading level0 row2\" >+Schema&AugColumn</th>\n",
              "      <td id=\"T_80b8b_row2_col0\" class=\"data row2 col0\" >90.000000</td>\n",
              "      <td id=\"T_80b8b_row2_col1\" class=\"data row2 col1\" >93.600000</td>\n",
              "      <td id=\"T_80b8b_row2_col2\" class=\"data row2 col2\" >76.200000</td>\n",
              "      <td id=\"T_80b8b_row2_col3\" class=\"data row2 col3\" >65.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_80b8b_level0_row3\" class=\"row_heading level0 row3\" >+Schema&AugSynonym</th>\n",
              "      <td id=\"T_80b8b_row3_col0\" class=\"data row3 col0\" ></td>\n",
              "      <td id=\"T_80b8b_row3_col1\" class=\"data row3 col1\" ></td>\n",
              "      <td id=\"T_80b8b_row3_col2\" class=\"data row3 col2\" >65.900000</td>\n",
              "      <td id=\"T_80b8b_row3_col3\" class=\"data row3 col3\" ></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write csv\n",
        "csv_file = os.path.join(projpath, \"saved_results\", \"finaltable.csv\")\n",
        "finaltable.to_csv(csv_file)\n"
      ],
      "metadata": {
        "id": "g-2RBb5xJPNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pmmxfHgggtag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0OUYkPy8tewg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correction Logic"
      ],
      "metadata": {
        "id": "fCbuGpq_Zs53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read db with embeddings\n",
        "result_file = os.path.join(projpath, \"test_emb_pickle\")\n",
        "dbfile = open(result_file, 'rb')     \n",
        "db = pickle.load(dbfile)\n",
        "dbfile.close()\n",
        "# sentence transformer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "st = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "\n",
        "def correctLogic(table_id, col, val):\n",
        "  \"\"\" Corrects column and its value based on closest embeddings distance\n",
        "      to the ones in the database\n",
        "  \"\"\"\n",
        "  # column\n",
        "  col_enc = st.encode(col)\n",
        "  header_emb = db[table_id][\"header_emb\"][0]\n",
        "  header_sim = cosine_similarity([col_enc], header_emb)\n",
        "  col_idx = np.argmax(header_sim)\n",
        "  col_correct = db[table_id][\"header\"][col_idx]\n",
        "  # value\n",
        "  val_emb = np.array(db[table_id][\"rows_emb\"])[:,col_idx]\n",
        "  val_enc = st.encode(q)\n",
        "  val_sim = cosine_similarity([val_enc], val_emb)\n",
        "  val_idx = np.argmax(val_sim)\n",
        "  val_correct = np.array(db[table_id][\"rows\"])[val_idx,col_idx]\n",
        "  return col_correct, val_correct\n",
        "\n",
        "def processConds(txt, table_id, correction=False):\n",
        "  \"\"\" Extract each where condition and post process it (strip, lowercase, sort for comparison).\n",
        "  \"\"\"\n",
        "  table_id = table_id.strip()\n",
        "  pattern = r'\\[(.*?)\\]'\n",
        "  extr_conds = re.findall(pattern, txt)\n",
        "  out = [c.strip().lower() for c in extr_conds]\n",
        "  out.sort()\n",
        "  if correction:\n",
        "    out_correct = out\n",
        "    for i in range(len(out_correct)):\n",
        "      et = re.findall(r\"(.+)equals to(.+)\", out_correct[i])\n",
        "      gt = re.findall(r\"(.+)greater than(.+)\", out_correct[i])\n",
        "      lt = re.findall(r\"(.+)less than(.+)\", out_correct[i])\n",
        "      correct_flag = False\n",
        "      if len(et) != 0:\n",
        "        if len(et[0]) == 2:\n",
        "          op = \"equals to\"\n",
        "          col = et[0][0].strip()\n",
        "          val = et[0][1].strip()\n",
        "          correct_flag = True\n",
        "      elif len(gt) != 0:\n",
        "        if len(gt[0]) == 2:\n",
        "          op = \"greater than\"\n",
        "          col = gt[0][0].strip()\n",
        "          val = gt[0][1].strip()\n",
        "          correct_flag = True     \n",
        "      elif len(lt) != 0:\n",
        "        if len(lt[0]) == 2:\n",
        "          op = \"less than\"\n",
        "          col = lt[0][0].strip()\n",
        "          val = lt[0][1].strip()\n",
        "          correct_flag = True   \n",
        "      else:\n",
        "        pass\n",
        "\n",
        "      if correct_flag:\n",
        "        col_correct, val_correct = correctLogic(table_id, col, val)\n",
        "        cond_correct = col_correct + \" \" + op + \" \" + val_correct\n",
        "        out_correct[i] = cond_correct.lower()      \n",
        "    out = out_correct\n",
        "  return out\n",
        "\n"
      ],
      "metadata": {
        "id": "M9D_KTWGZ3FC"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_label = trans_exp0.conds_df[\"pred_label\"][-5:]\n",
        "table_id = table_id_df[\"table_id\"][-5:]\n",
        "true_label = trans_exp0.conds_df[\"true_label_proc\"][-5:]\n",
        "numcorrect = 0\n",
        "for (i, (pr,id,tr)) in enumerate(zip(pred_label, table_id, true_label)):\n",
        "  pred_correct = processConds(pr, id, correction=True)\n",
        "  if pred_correct == tr:\n",
        "    numcorrect += 1\n",
        "\n",
        "acc_correct = numcorrect / len(pred_label)\n",
        "\n"
      ],
      "metadata": {
        "id": "Jphw-cWz0_so"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dJua1hEA7JLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "16cpriv5dEeb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}